---
slug: /
---

# Introduction
Cogkit is a powerful framework for working with cognitive AI models, focusing on multimodal generation and fine-tuning capabilities. It provides a unified interface for various AI tasks including text-to-image, text-to-video, and image-to-video generation.

## Key Features

- **Command-line Interface**: Easy-to-use CLI and Python API for both inference and fine-tuning

- **Fine-tuning Support**: With LoRA or full model finetuning support to customize models with your own data

## Supported Models

Cogkit supports a wide range of models from Hugging Face, including:

<!-- FIXME: add links to the models -->
- Stable Diffusion models for text-to-image generation
- Stable Video Diffusion models for video generation
- Custom fine-tuned models

<!-- FIXME: add model card links -->

## Getting Started

To get started with Cogkit, check out the [Installation](./02-Installation.md) guide, then explore the [Inference](./03-Inference/02-API.md) and [Fine-tuning](./04-Finetune/01-Prerequisites.md) documentation.

## Project Status

Cogkit is under active development, we welcome contributions and feedback from the community.

## Troubleshooting & Disscussion

<!-- FIXME: add link to the issues pages -->
For more detailed troubleshooting (bug related issues), please refer to our GitHub issues page.

<!-- FIXME: add link to wechat? discord? or github disccussions? -->
For general discussions and support, please join our [Discord server](https://discord.gg/cogmodels).

## License

<!-- FIXME: LICENSE file is not present in the repo -->

<!-- Cogkit is licensed under the [MIT License](./LICENSE). -->
